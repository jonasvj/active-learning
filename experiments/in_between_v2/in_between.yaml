seed: 0
data_path: experiments/in_between_v2/run_all_data

# Data hyperparameters
data:
  data_class: OriginDataset
  data_hparams:
    batch_size: 100

# Model hyperparameters
model:
  model_class: RegressionFNN
  model_hparams:
    n_in: 2
    n_out: 1
    hidden_sizes: [50]
    drop_probs: [0.05]
    sigma_noise: 0.1
    sigma_b: 1.
    sigma_w: 4.
    sigma_default: 4.
    scale_sigma_w_by_dim: true
    use_prior: true
    device: cuda

# MAP hyperparameters
fit_model_hparams:
    n_epochs: 100000
    lr: 1e-3
    cosine_annealing: false
    weight_decay: 0
    dynamic_weight_decay: false
    early_stopping_patience: null
    min_epochs: null
    init_params: null

# Key for selecting inference methods
inference_key: mcdo

# Number of monte carlo samples
mc_samples: 500

# Deterministic (just uses MAP estimate)
deterministic:
  inference_class: Deterministic
  init_hparams: {}
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}

# Deep ensemble
ensemble:
  inference_class: Ensemble
  init_hparams:
    n_components: 10
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}

# Monte carlo dropout
mcdo:
  inference_class: MonteCarloDropout
  init_hparams:
    n_posterior_samples: ${mc_samples}
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}

# Laplace approximation
laplace:
  inference_class: LaplaceApproximation
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: last_layer
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_laplace_hparams:
      hessian_structure: full
      optimize_precision: true
      prior_precision: null

# Ensemble of Laplace approximations
laplace_ensemble:
  inference_class: LaplaceEnsemble
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: ${laplace.init_hparams.subset_of_weights}
    n_components: 10
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_laplace_hparams: ${laplace.fit_hparams.fit_laplace_hparams}
    covar_scale: 1.

# Laplace approximation refined by normalizing flow
laplace_nf:
  inference_class: NFRefinedLastLayerLaplace
  init_hparams:
    n_posterior_samples: ${mc_samples}
  fit_hparams: 
    fit_model_hparams: ${fit_model_hparams}
    fit_laplace_hparams: ${laplace.fit_hparams.fit_laplace_hparams}
    fit_flow_hparams:
      n_epochs: 100000
      lr: 1e-3
      cosine_annealing: false
      transform: Radial
      n_transforms: 10
      num_particles: 32

# SWAG
swag:
  inference_class: SWAG
  init_hparams:
    K: 1000
    n_posterior_samples: ${mc_samples}
    sequential_samples: False
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_swag_hparams:
      swag_batch_size: 10
      swag_epochs: 1000
      swag_lr: 1e-3
      swag_weight_decay: ${fit_model_hparams.weight_decay}
      swag_momentum: 0.9
      clip_value: null
      save_iterates: false
      drop_out: false
      val_criterion: lpd
      drop_last: true

# SWAG with scale of covariance matrix optimized by svi
swag_svi:
  inference_class: SWAGSVI
  init_hparams: ${swag.init_hparams}
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_swag_hparams:
      swag_batch_size: ${swag.fit_hparams.fit_swag_hparams.swag_batch_size}
      swag_epochs: ${swag.fit_hparams.fit_swag_hparams.swag_epochs}
      swag_lr: 1e-3
      swag_weight_decay: ${swag.fit_hparams.fit_swag_hparams.swag_weight_decay}
      swag_momentum: ${swag.fit_hparams.fit_swag_hparams.swag_momentum}
      clip_value: ${swag.fit_hparams.fit_swag_hparams.clip_value}
      save_iterates: ${swag.fit_hparams.fit_swag_hparams.save_iterates}
      drop_out: ${swag.fit_hparams.fit_swag_hparams.drop_out}
      val_criterion: ${swag.fit_hparams.fit_swag_hparams.val_criterion}
      drop_last: ${swag.fit_hparams.fit_swag_hparams.drop_last}
    fit_covar_hparams:
      svi_lr: 1e-2
      svi_epochs: 1000
      mini_batch: true
      n_variational_samples: 32
      sequential_samples: false
      batch_norm_subset: null


# MFVI
mfvi:
  inference_class: VI
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: all
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_vi_hparams:
      n_epochs: 100000
      lr: 1e-3
      cosine_annealing: false
      guide: diagonal
      num_particles: 32
      init_scale: 1e-4
      init_params: null

# Full-rank VI
frvi:
  inference_class: VI
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: all
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_vi_hparams:
      n_epochs: 100000
      lr: 1e-3
      cosine_annealing: false
      guide: multivariate
      num_particles: 32
      init_scale: 1e-4
      init_params: null

# LL MFVI
mfvi_ll:
  inference_class: VI
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: last_layer
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_vi_hparams:
      n_epochs: 100000
      lr: 1e-3
      cosine_annealing: false
      guide: diagonal
      num_particles: 32
      init_scale: 1e-4
      init_params: null

# LL full-rank VI
frvi_ll:
  inference_class: VI
  init_hparams:
    n_posterior_samples: ${mc_samples}
    subset_of_weights: last_layer
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_vi_hparams:
      n_epochs: 100000
      lr: 1e-3
      cosine_annealing: false
      guide: multivariate
      num_particles: 32
      init_scale: 1e-4
      init_params: null

hmc:
  inference_class: HMC
  init_hparams:
    n_posterior_samples: 250000
    subset_of_weights: all
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_hmc_hparams:
      warmup_steps: 10000
      num_chains: 1
      max_tree_depth: 5

hmc_ll:
  inference_class: HMC
  init_hparams:
    n_posterior_samples: 250000
    subset_of_weights: 'last_layer'
  fit_hparams:
    fit_model_hparams: ${fit_model_hparams}
    fit_hmc_hparams:
      warmup_steps: 10000
      num_chains: 1
      max_tree_depth: 5